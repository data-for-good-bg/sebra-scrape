{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034754ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052257fd",
   "metadata": {},
   "source": [
    "# Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed93ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_link = 'https://docs.google.com/spreadsheets/d/1VoB4dIH2Y2x2O-eH0ivNmBUYCcT-1NR6T5h8eWkE33Y/gviz/tq?tqx=out:csv&gid=1639699984'\n",
    "df = pd.read_csv(data_link, index_col=0)\n",
    "\n",
    "df['Start Date'] = pd.to_datetime(df['Start Date'])\n",
    "df['End Date'] = pd.to_datetime(df['End Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c83b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_org = df.groupby(['Organization Name', 'Organization ID', 'Category', 'Start Date'], as_index=False).sum()\n",
    "df_grouped_by_op = df.groupby(['Operations Code', 'Operations Description', 'Start Date'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_org_name = list(df['Organization Name'].unique())\n",
    "id2name = {}\n",
    "for org_name in unique_org_name:\n",
    "    nm = org_name.split(' ( ')[0]\n",
    "    org_id = org_name.split(' ( ')[-1].split()[0]\n",
    "    id2name[org_id] = nm\n",
    "    \n",
    "    \n",
    "unique_ops = df[['Operations Code', 'Operations Description']].drop_duplicates()\n",
    "code2operation = {}\n",
    "for _, row in unique_ops.iterrows():\n",
    "    code = row['Operations Code']\n",
    "    op = row['Operations Description']\n",
    "    code2operation[code] = op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf14e22",
   "metadata": {},
   "source": [
    "# Anomaly/Outlier detection\n",
    "\n",
    "## Calc summary stats\n",
    "\n",
    "Here, we are calculating the mean, 1Q, 3Q, IQR, and standard deviation for each organization and for each operation.\n",
    "With these, we can classify outliers assuming the data is normaly distributed or using the IQR rule.\n",
    "\n",
    "Using the first method, a point is an oulier if it is more than two standard deviations away from the average.\n",
    "Using the second method, a point is an oulier if it is more than 1.5 IQR higher than the 3rd quartile or 1.5 IQR lower than the 1st quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1716da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(series):\n",
    "    res = {}\n",
    "    res['mean'] = me =  np.mean(series)\n",
    "    res['std'] = std = np.std(series)\n",
    "    res['norm_low'] = me - 2*std\n",
    "    res['norm_high'] = me + 2*std\n",
    "    \n",
    "    qs = np.quantile(series, [0.25, 0.75])\n",
    "\n",
    "    res['1Q'] = qs[0]\n",
    "    res['3Q'] = qs[1]\n",
    "    res['iqr'] = iqr = qs[1]-qs[0]\n",
    "    res['iqr_low'] = qs[0] - 1.5*iqr\n",
    "    res['iqr_high'] = qs[1] + 1.5*iqr\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282be951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id2stats = {}\n",
    "code2stats = {}\n",
    "\n",
    "for org_id, _ in id2name.items():\n",
    "    org_payments = df_grouped_by_org[(df_grouped_by_org['Organization ID']==org_id)].copy()\n",
    "\n",
    "    id2stats[org_id] = {}\n",
    "    if org_payments.shape[0] > 1:\n",
    "        \n",
    "        id2stats[org_id]['nonzero'] = calc_stats(org_payments['Operations Amount (BGN)'])\n",
    "        \n",
    "        date_fill_df = pd.DataFrame({\n",
    "            'Start Date': pd.date_range(org_payments['Start Date'].min(), org_payments['Start Date'].max())\n",
    "        })\n",
    "        org_payments = date_fill_df.merge(org_payments, on='Start Date', how='left')\n",
    "        org_payments['Operations Amount (BGN)'].fillna(0, inplace=True)\n",
    "        \n",
    "        id2stats[org_id]['zerofilled'] = calc_stats(org_payments['Operations Amount (BGN)'])\n",
    "\n",
    "        \n",
    "for cd, org_name in code2operation.items():\n",
    "    op_payments = df_grouped_by_op[(df_grouped_by_op['Operations Code']==cd)].copy()   \n",
    "    code2stats[cd] = {}\n",
    "    if op_payments.shape[0] > 1:\n",
    "        code2stats[cd]['nonzero'] = calc_stats(op_payments['Operations Amount (BGN)'])\n",
    "        \n",
    "        date_fill_df = pd.DataFrame({\n",
    "            'Start Date': pd.date_range(op_payments['Start Date'].min(), op_payments['Start Date'].max())\n",
    "        })\n",
    "        op_payments = date_fill_df.merge(op_payments, on='Start Date', how='left')\n",
    "        op_payments['Operations Amount (BGN)'].fillna(0, inplace=True)\n",
    "        \n",
    "        code2stats[cd]['zerofilled'] = calc_stats(op_payments['Operations Amount (BGN)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_payments_norm(row, stats_dict):\n",
    "    payment = row['Operations Amount (BGN)']\n",
    "    \n",
    "    norm_nonzero = 1*(\n",
    "        (payment > stats_dict['norm_high']) or \n",
    "        ((payment < stats_dict['norm_low']))\n",
    "    )\n",
    "    return norm_nonzero\n",
    "    \n",
    "    \n",
    "def classify_payments_iqr(row, stats_dict):    \n",
    "    payment = row['Operations Amount (BGN)']    \n",
    "    iqr_nonzero = 1*(\n",
    "        (payment > stats_dict['iqr_high']) or \n",
    "        ((payment < stats_dict['iqr_low']))\n",
    "    )\n",
    "    return iqr_nonzero\n",
    "\n",
    "\n",
    "def if_org_id(row, key, fn):\n",
    "    if id2stats[row['Organization ID']]=={}:\n",
    "        return np.nan\n",
    "    return fn(row, id2stats[row['Organization ID']][key])\n",
    "    \n",
    "\n",
    "def if_code_id(row, key, fn):\n",
    "    if code2stats[row['Operations Code']]=={}:\n",
    "        return np.nan\n",
    "    return fn(row, code2stats[row['Operations Code']][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa538ffe",
   "metadata": {},
   "source": [
    "## Classify data points by Organization ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3ec67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_grouped_by_org['anomaly_norm_nonzero'] = df_grouped_by_org.apply(\n",
    "    lambda row: if_org_id(row, 'nonzero', classify_payments_norm),\n",
    "    axis=1\n",
    ")\n",
    "df_grouped_by_org['anomaly_norm_zerofilled'] = df_grouped_by_org.apply(\n",
    "    lambda row: if_org_id(row, 'zerofilled', classify_payments_norm),\n",
    "    axis=1\n",
    ")\n",
    "df_grouped_by_org['anomaly_iqr_nonzero'] = df_grouped_by_org.apply(\n",
    "    lambda row: if_org_id(row, 'nonzero', classify_payments_iqr),\n",
    "    axis=1\n",
    ")\n",
    "df_grouped_by_org['anomaly_iqr_zerofilled'] = df_grouped_by_org.apply(\n",
    "    lambda row: if_org_id(row, 'zerofilled', classify_payments_iqr),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "np.around(100*df_grouped_by_org[\n",
    "    [c for c in df_grouped_by_org.columns if \"anomaly\" in c]\n",
    "].sum()/df_grouped_by_org.shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938097e",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ae024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anomaly_choice_norm = 'anomaly_norm_nonzero'\n",
    "\n",
    "for org_id, org_name in id2name.items():\n",
    "    org_payments = df_grouped_by_org[\n",
    "        (df_grouped_by_org['Organization ID']==org_id) &\n",
    "        (df_grouped_by_org['Start Date'] >= pd.Timestamp('2021-01-01')) &\n",
    "        (df_grouped_by_org['Start Date'] < pd.Timestamp('2022-01-01'))\n",
    "    ].copy() \n",
    "    anomalies_norm = org_payments[org_payments[anomaly_choice_norm]>0].copy()\n",
    "    \n",
    "    if org_payments.shape[0] > 0:\n",
    "        date_fill_df = pd.DataFrame({\n",
    "            'Start Date': pd.date_range(org_payments['Start Date'].min(), org_payments['Start Date'].max())\n",
    "        })\n",
    "        org_payments = date_fill_df.merge(org_payments, on='Start Date', how='left')\n",
    "        org_payments['Operations Amount (BGN)'].fillna(0, inplace=True)\n",
    "        min_pay = org_payments['Operations Amount (BGN)'].min()\n",
    "        max_pay = org_payments['Operations Amount (BGN)'].max()\n",
    "        \n",
    "        labels = [\"Плащания\", 0]\n",
    "        \n",
    "        plt.figure(figsize=(15, 9))\n",
    "        plt.plot(org_payments['Start Date'], org_payments['Operations Amount (BGN)'], marker=\"o\", linestyle=\"dashed\")\n",
    "        plt.vlines(anomalies_norm['Start Date'], min_pay, max_pay, colors='purple', alpha=0.5)\n",
    "        plt.axhline(y=0, c='grey', alpha=0.5)\n",
    "        \n",
    "        if id2stats[org_id]!={}:\n",
    "            plt.axhline(y=id2stats[org_id]['nonzero']['norm_high'], c='tab:blue', linestyle=\"--\", alpha=0.5)\n",
    "            plt.axhline(y=id2stats[org_id]['nonzero']['norm_low'], c='tab:blue', linestyle=\"--\", alpha=0.5)\n",
    "            labels.append('Горна граница')\n",
    "            labels.append('Долна граница')\n",
    "        \n",
    "        \n",
    "        if anomalies_norm.shape[0] > 0:\n",
    "            labels.append(\"Аномалии\")\n",
    "            \n",
    "        plt.legend(labels)\n",
    "        plt.title(f\"{org_name}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5da40",
   "metadata": {},
   "source": [
    "## Classify data points by Operations Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49238238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_grouped_by_op['anomaly_norm_nonzero'] = df_grouped_by_op.apply(\n",
    "    lambda row: if_code_id(row, 'nonzero', classify_payments_norm),\n",
    "    axis=1\n",
    ")\n",
    "df_grouped_by_op['anomaly_norm_zerofilled'] = df_grouped_by_op.apply(\n",
    "    lambda row: if_code_id(row, 'zerofilled', classify_payments_norm),\n",
    "    axis=1\n",
    ")\n",
    "df_grouped_by_op['anomaly_iqr_nonzero'] = df_grouped_by_op.apply(\n",
    "    lambda row: if_code_id(row, 'nonzero', classify_payments_iqr),\n",
    "    axis=1\n",
    ")\n",
    "df_grouped_by_op['anomaly_iqr_zerofilled'] = df_grouped_by_op.apply(\n",
    "    lambda row: if_code_id(row, 'zerofilled', classify_payments_iqr),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "np.around(100*df_grouped_by_op[\n",
    "    [c for c in df_grouped_by_op.columns if \"anomaly\" in c]\n",
    "].sum()/df_grouped_by_op.shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4415a24",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3051f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anomaly_choice_norm = 'anomaly_norm_nonzero'\n",
    "\n",
    "for code, op in code2operation.items():\n",
    "    op_payments = df_grouped_by_op[\n",
    "        (df_grouped_by_op['Operations Code']==code) &\n",
    "        (df_grouped_by_op['Start Date'] >= pd.Timestamp('2021-11-01')) &\n",
    "        (df_grouped_by_op['Start Date'] < pd.Timestamp('2023-01-01'))\n",
    "    ].copy() \n",
    "    anomalies_norm = op_payments[op_payments[anomaly_choice_norm]>0].copy()\n",
    "    \n",
    "    if op_payments.shape[0] > 0:\n",
    "        date_fill_df = pd.DataFrame({\n",
    "            'Start Date': pd.date_range(op_payments['Start Date'].min(), op_payments['Start Date'].max())\n",
    "        })\n",
    "        op_payments = date_fill_df.merge(op_payments, on='Start Date', how='left')\n",
    "        op_payments['Operations Amount (BGN)'].fillna(0, inplace=True)\n",
    "        min_pay = op_payments['Operations Amount (BGN)'].min()\n",
    "        max_pay = op_payments['Operations Amount (BGN)'].max()\n",
    "        \n",
    "        labels=[\"Плащания\", 0,]\n",
    "        plt.figure(figsize=(15, 9))\n",
    "        plt.plot(op_payments['Start Date'], op_payments['Operations Amount (BGN)'], marker=\"o\", linestyle=\"dashed\")\n",
    "        plt.vlines(anomalies_norm['Start Date'], min_pay, max_pay, colors='purple', alpha=0.5)\n",
    "        plt.axhline(y=0, c='grey', alpha=0.5)\n",
    "        \n",
    "        if code2stats[code]!={}:\n",
    "            plt.axhline(y=code2stats[code]['nonzero']['norm_high'], c='tab:blue', linestyle=\"--\", alpha=0.5)\n",
    "            plt.axhline(y=code2stats[code]['nonzero']['norm_low'], c='tab:blue', linestyle=\"--\", alpha=0.5)\n",
    "            labels.append('Горна граница')\n",
    "            labels.append('Долна граница')\n",
    "        \n",
    "        if anomalies_norm.shape[0] > 0:\n",
    "            labels.append('Аномалии')\n",
    "            \n",
    "        plt.legend(labels)\n",
    "        plt.title(f\"{op} {code}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f031979",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------\n",
    "# Investigate EoY big spendings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_org = df_grouped_by_org.copy()\n",
    "df_by_org['month'] = df_by_org['Start Date'].dt.month\n",
    "df_by_org['year'] = df_by_org['Start Date'].dt.year\n",
    "df_by_org['week'] = df_by_org['Start Date'].dt.week\n",
    "# df_by_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7135884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_org_weekly = df_by_org.groupby(\n",
    "    ['Organization Name', 'Organization ID', 'Category', 'year', 'week']\n",
    ")['Operations Amount (BGN)'].sum().reset_index().rename(\n",
    "    columns={'Operations Amount (BGN)': 'spending_BGN'}\n",
    ")\n",
    "\n",
    "df_by_org_monthly = df_by_org.groupby(\n",
    "    ['Organization Name', 'Organization ID', 'Category', 'year', 'month']\n",
    ")['Operations Amount (BGN)'].sum().reset_index().rename(\n",
    "    columns={'Operations Amount (BGN)': 'spending_BGN'}\n",
    ")\n",
    "# df_by_org_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bb332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly avgs\n",
    "weekly_avg_yearly = df_by_org_weekly.groupby(\n",
    "    ['Organization Name', 'Organization ID', 'Category', 'year']\n",
    ")['spending_BGN'].mean().reset_index().rename(\n",
    "    columns={'spending_BGN': 'weekly_avg_yearly'}\n",
    ")\n",
    "\n",
    "weekly_avg_overall = df_by_org_weekly.groupby(\n",
    "    ['Organization Name', 'Organization ID', 'Category']\n",
    ")['spending_BGN'].mean().reset_index().rename(\n",
    "    columns={'Operations Amount (BGN)': 'weekly_avg_overall'}\n",
    ")\n",
    "\n",
    "weekly_avg_over_years = df_by_org_weekly.groupby(\n",
    "    ['Organization Name', 'Organization ID', 'Category', 'week']\n",
    ")['spending_BGN'].mean().reset_index().rename(\n",
    "    columns={'spending_BGN': 'weekly_avg_over_years'}\n",
    ")\n",
    "\n",
    "\n",
    "# Monthly avgs\n",
    "monthly_avg_yearly = df_by_org_monthly.groupby(\n",
    "    ['Organization Name', 'Organization ID', 'Category', 'year']\n",
    ")['spending_BGN'].mean().reset_index().rename(\n",
    "    columns={'spending_BGN': 'monthly_avg_yearly'}\n",
    ")\n",
    "\n",
    "monthly_avg_overall = df_by_org_monthly.groupby(\n",
    "    ['Organization Name', 'Organization ID', 'Category']\n",
    ")['spending_BGN'].mean().reset_index().rename(\n",
    "    columns={'spending_BGN': 'monthly_avg_overall'}\n",
    ")\n",
    "\n",
    "monthly_avg_over_years = df_by_org_monthly.groupby(\n",
    "    ['Organization Name', 'Organization ID', 'Category', 'month']\n",
    ")['spending_BGN'].sum().reset_index().rename(\n",
    "    columns={'spending_BGN': 'monthly_avg_over_years'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb09d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_org_monthly = df_by_org_monthly.merge(\n",
    "    monthly_avg_yearly, \n",
    "    on=['Organization Name', 'Organization ID', 'Category', 'year']\n",
    ")\n",
    "df_by_org_monthly['deviation_from_monthly_avg_yearly'] = np.around(\n",
    "    df_by_org_monthly.spending_BGN - df_by_org_monthly.monthly_avg_yearly, 2\n",
    ")\n",
    "\n",
    "\n",
    "df_by_org_monthly = df_by_org_monthly.merge(\n",
    "    monthly_avg_over_years, \n",
    "    on=['Organization Name', 'Organization ID', 'Category', 'month']\n",
    ")\n",
    "df_by_org_monthly['deviation_from_monthly_avg_over_years'] = np.around(\n",
    "    df_by_org_monthly.spending_BGN - df_by_org_monthly.monthly_avg_over_years, 2\n",
    ")\n",
    "\n",
    "\n",
    "df_by_org_monthly = df_by_org_monthly.merge(\n",
    "    monthly_avg_overall, \n",
    "    on=['Organization Name', 'Organization ID', 'Category']\n",
    ")\n",
    "df_by_org_monthly['deviation_from_monthly_avg_overall'] = np.around(\n",
    "    df_by_org_monthly.spending_BGN - df_by_org_monthly.monthly_avg_overall, 2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d1383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_by_org_monthly[\n",
    "#     (df_by_org_monthly.year==2021) & (df_by_org_monthly.month==12)\n",
    "# ].sort_values(\n",
    "#     'deviation_from_monthly_avg_yearly',\n",
    "#     ascending=False\n",
    "# ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d39d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_by_org_monthly[\n",
    "#     (df_by_org_monthly.year==2021) & (df_by_org_monthly.month==12)\n",
    "# ].sort_values(\n",
    "#     'deviation_from_monthly_avg_yearly',\n",
    "#     ascending=False\n",
    "# ).reset_index(drop=True).to_csv(\"monthly_deviations_from_mean_by_organization.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed94f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
